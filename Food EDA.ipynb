{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#standard Data Science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "#import gensim stuff\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "#import sklearn utilities\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#other\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165256</th>\n",
       "      <td>165257</td>\n",
       "      <td>B000EVG8J2</td>\n",
       "      <td>A1L01D2BD3RKVO</td>\n",
       "      <td>B. Miller \"pet person\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1268179200</td>\n",
       "      <td>Crunchy &amp; Good Gluten-Free Sandwich Cookies!</td>\n",
       "      <td>Having tried a couple of other brands of glute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231465</th>\n",
       "      <td>231466</td>\n",
       "      <td>B0000BXJIS</td>\n",
       "      <td>A3U62RE5XZDP0G</td>\n",
       "      <td>Marty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1298937600</td>\n",
       "      <td>great kitty treats</td>\n",
       "      <td>My cat loves these treats. If ever I can't fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427827</th>\n",
       "      <td>427828</td>\n",
       "      <td>B008FHUFAU</td>\n",
       "      <td>AOXC0JQQZGGB6</td>\n",
       "      <td>Kenneth Shevlin</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1224028800</td>\n",
       "      <td>COFFEE TASTE</td>\n",
       "      <td>A little less than I expected.  It tends to ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433954</th>\n",
       "      <td>433955</td>\n",
       "      <td>B006BXV14E</td>\n",
       "      <td>A3PWPNZVMNX3PA</td>\n",
       "      <td>rareoopdvds</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1335312000</td>\n",
       "      <td>So the Mini-Wheats were too big?</td>\n",
       "      <td>First there was Frosted Mini-Wheats, in origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70260</th>\n",
       "      <td>70261</td>\n",
       "      <td>B007I7Z3Z0</td>\n",
       "      <td>A1XNZ7PCE45KK7</td>\n",
       "      <td>Og8ys1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>Great Taste . . .</td>\n",
       "      <td>and I want to congratulate the graphic artist ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId             ProfileName  \\\n",
       "165256  165257  B000EVG8J2  A1L01D2BD3RKVO  B. Miller \"pet person\"   \n",
       "231465  231466  B0000BXJIS  A3U62RE5XZDP0G                   Marty   \n",
       "427827  427828  B008FHUFAU   AOXC0JQQZGGB6         Kenneth Shevlin   \n",
       "433954  433955  B006BXV14E  A3PWPNZVMNX3PA             rareoopdvds   \n",
       "70260    70261  B007I7Z3Z0  A1XNZ7PCE45KK7                  Og8ys1   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "165256                     0                       0      5  1268179200   \n",
       "231465                     0                       0      5  1298937600   \n",
       "427827                     0                       2      3  1224028800   \n",
       "433954                     0                       1      2  1335312000   \n",
       "70260                      0                       2      5  1334707200   \n",
       "\n",
       "                                             Summary  \\\n",
       "165256  Crunchy & Good Gluten-Free Sandwich Cookies!   \n",
       "231465                            great kitty treats   \n",
       "427827                                  COFFEE TASTE   \n",
       "433954              So the Mini-Wheats were too big?   \n",
       "70260                              Great Taste . . .   \n",
       "\n",
       "                                                     Text  \n",
       "165256  Having tried a couple of other brands of glute...  \n",
       "231465  My cat loves these treats. If ever I can't fin...  \n",
       "427827  A little less than I expected.  It tends to ha...  \n",
       "433954  First there was Frosted Mini-Wheats, in origin...  \n",
       "70260   and I want to congratulate the graphic artist ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the dataset, split into workable subset\n",
    "reviews_full = pd.read_csv(\"/Users/anagiraldo-w/ds/Portfolio/Fine Food Reviews/data/reviews.csv\")\n",
    "reviews_bulk, reviews = train_test_split(reviews_full, test_size = 0.1, random_state = 42)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>374342</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1B2IZU1JLZA6</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>WARNING: CLAMSHELL EDITION IS EDITED TV VERSION</td>\n",
       "      <td>I, myself always enjoyed this movie, it's very...</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230268</td>\n",
       "      <td>B00004RYGX</td>\n",
       "      <td>A1B2IZU1JLZA6</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>WARNING: CLAMSHELL EDITION IS EDITED TV VERSION</td>\n",
       "      <td>I, myself always enjoyed this movie, it's very...</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451976</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>ACJR7EQF9S6FP</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>Bettlejuice...Bettlejuice...BETTLEJUICE!</td>\n",
       "      <td>What happens when you say his name three times...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149769</td>\n",
       "      <td>B00004S1C5</td>\n",
       "      <td>A1KXONFPU2XQ5K</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-08-09</td>\n",
       "      <td>Very easy to use</td>\n",
       "      <td>This are so much easier to use than the Wilson...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479722</td>\n",
       "      <td>B00005U2FA</td>\n",
       "      <td>A3TO9GEQEGKFDC</td>\n",
       "      <td>5</td>\n",
       "      <td>2002-05-01</td>\n",
       "      <td>I love this thing</td>\n",
       "      <td>The wine saver is great in so many ways. Obvio...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   ProductId          UserId  Score       Time  \\\n",
       "0  374342  B00004CI84   A1B2IZU1JLZA6      1 2000-01-19   \n",
       "1  230268  B00004RYGX   A1B2IZU1JLZA6      1 2000-01-19   \n",
       "2  451976  B00004CXX9   ACJR7EQF9S6FP      4 2000-02-26   \n",
       "3  149769  B00004S1C5  A1KXONFPU2XQ5K      5 2000-08-09   \n",
       "4  479722  B00005U2FA  A3TO9GEQEGKFDC      5 2002-05-01   \n",
       "\n",
       "                                           Summary  \\\n",
       "0  WARNING: CLAMSHELL EDITION IS EDITED TV VERSION   \n",
       "1  WARNING: CLAMSHELL EDITION IS EDITED TV VERSION   \n",
       "2         Bettlejuice...Bettlejuice...BETTLEJUICE!   \n",
       "3                                 Very easy to use   \n",
       "4                                I love this thing   \n",
       "\n",
       "                                                Text  Helpfulness  \n",
       "0  I, myself always enjoyed this movie, it's very...     0.826087  \n",
       "1  I, myself always enjoyed this movie, it's very...     0.826087  \n",
       "2  What happens when you say his name three times...     0.666667  \n",
       "3  This are so much easier to use than the Wilson...     1.000000  \n",
       "4  The wine saver is great in so many ways. Obvio...     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Time'] = pd.to_datetime(reviews['Time'], unit='s')\n",
    "reviews['Helpfulness'] = reviews['HelpfulnessNumerator']/reviews['HelpfulnessDenominator']\n",
    "reviews = reviews.drop(['Id', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'ProfileName'], axis=1)\n",
    "reviews = reviews.sort_values(by='Time').reset_index()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index              0\n",
       "ProductId          0\n",
       "UserId             0\n",
       "Score              0\n",
       "Time               0\n",
       "Summary            1\n",
       "Text               0\n",
       "Helpfulness    27004\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews['Helpfulness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5249621785173979"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(reviews['Helpfulness']) - 27004)/len(reviews['Helpfulness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out textual data column\n",
    "\n",
    "text = reviews['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stops = ['http', 'www', 'br', 'gp', 'com', 'href', 've', 'don', 'really', 'product', 'eat', 'amazon', 'bit', 'eating']\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 1),\n",
    "                        analyzer='word',\n",
    "                        stop_words=stop_words,\n",
    "                        strip_accents='unicode',\n",
    "                        max_df=0.05\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56846, 44337)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = tfidf.fit_transform(text)\n",
    "tfidf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1),\n",
    "                      analyzer='word',\n",
    "                      stop_words=stop_words,\n",
    "                      strip_accents='unicode',\n",
    "                      max_df=0.11\n",
    "                     )\n",
    "vec.fit(text)\n",
    "\n",
    "counts_vec = vec.transform(text).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(15)\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.get_feature_names()\n",
    "topics = [[features[idx] for idx in np.flip(np.argsort(component)[-20:])] for component in nmf.components_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(topics):\n",
    "    for i,topic in enumerate(topics):\n",
    "        print(\"Topic {}\".format(i))\n",
    "        print(\", \".join(topic)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "hot, sauce, spicy, cocoa, heat, cold, iced, sauces, chicken, milk, pepper, soup, noodles, bottle, cheese, spice, chili, ice, kick, garlic\n",
      "\n",
      "Topic 1\n",
      "treats, dogs, treat, training, size, teeth, chew, puppy, chicken, pieces, toy, smell, picky, pet, smaller, large, bones, ingredients, giving, chews\n",
      "\n",
      "Topic 2\n",
      "chips, potato, chip, bags, kettle, fat, salty, snack, crunchy, vinegar, popchips, bbq, calories, spicy, regular, tortilla, baked, healthier, corn, alternative\n",
      "\n",
      "Topic 3\n",
      "bars, snack, bar, protein, candy, tasty, kind, low, calories, granola, fat, fruit, nuts, high, filling, almonds, crunchy, meal, grams, ingredients\n",
      "\n",
      "Topic 4\n",
      "cat, cats, chicken, dry, canned, foods, wellness, diet, ingredients, vet, wet, feed, tuna, feeding, grain, cans, picky, fish, science, meat\n",
      "\n",
      "Topic 5\n",
      "cookies, cookie, ginger, soft, chip, oatmeal, broken, package, shortbread, chewy, crunchy, kids, tasty, oreos, pamela, treat, oreo, ahoy, crispy, murray\n",
      "\n",
      "Topic 6\n",
      "strong, cups, bold, roast, bitter, dark, blend, keurig, smooth, coffees, french, starbucks, rich, decaf, morning, flavored, brew, medium, vanilla, weak\n",
      "\n",
      "Topic 7\n",
      "butter, peanut, calories, fat, pb2, low, peanuts, regular, almond, protein, pb, jar, cookie, spread, natural, creamy, powder, shakes, cream, real\n",
      "\n",
      "Topic 8\n",
      "stores, local, shipping, buying, happy, purchase, grocery, arrived, fresh, item, hard, received, pack, purchased, came, bags, package, quickly, fast, cheaper\n",
      "\n",
      "Topic 9\n",
      "coconut, oil, hair, olive, skin, cooking, using, smell, organic, natural, bottle, zico, oils, smells, nutiva, virgin, ingredients, body, conditioner, brands\n",
      "\n",
      "Topic 10\n",
      "cereal, milk, oatmeal, breakfast, organic, baby, cereals, fiber, granola, vanilla, rice, crunchy, cinnamon, honey, kids, yogurt, fruit, bowl, crunch, morning\n",
      "\n",
      "Topic 11\n",
      "salt, sea, vinegar, salty, pepper, almonds, sodium, himalayan, table, salts, soup, jerky, pink, seasoning, low, grinder, garlic, chicken, added, spice\n",
      "\n",
      "Topic 12\n",
      "popcorn, movie, popper, pop, theater, kernels, machine, popped, pops, easy, corn, northern, microwave, oil, popping, home, size, snack, salty, unpopped\n",
      "\n",
      "Topic 13\n",
      "green, teas, stash, black, organic, mountain, earl, grey, chai, drinking, lemon, ginger, iced, bags, enjoy, mint, honey, caffeine, white, loose\n",
      "\n",
      "Topic 14\n",
      "gluten, bread, pasta, wheat, flour, rice, texture, products, family, easy, pretzels, cheese, regular, diet, crackers, gf, baking, corn, cake, kids\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topics(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the topics across the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    26893\n",
       "6     6895\n",
       "3     4478\n",
       "1     3747\n",
       "9     3608\n",
       "0     3098\n",
       "4     2707\n",
       "5     2269\n",
       "2     1853\n",
       "7     1298\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([])\n",
    "df['topic']=[nmf_vec.argmax() for nmf_vec in nmf_vecs]\n",
    "\n",
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Try LDA ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"order\" + 0.014*\"store\" + 0.010*\"ordered\" + 0.010*\"box\" + 0.008*\"local\" + 0.008*\"bought\" + 0.007*\"shipping\" + 0.007*\"received\" + 0.007*\"stores\" + 0.007*\"arrived\"'),\n",
       " (1,\n",
       "  '0.018*\"chocolate\" + 0.014*\"treats\" + 0.012*\"dog\" + 0.011*\"butter\" + 0.011*\"treat\" + 0.009*\"dogs\" + 0.009*\"cookies\" + 0.009*\"bars\" + 0.008*\"peanut\" + 0.008*\"loves\"'),\n",
       " (2,\n",
       "  '0.036*\"tea\" + 0.020*\"cup\" + 0.011*\"drink\" + 0.009*\"cups\" + 0.009*\"strong\" + 0.008*\"green\" + 0.007*\"try\" + 0.006*\"make\" + 0.006*\"water\" + 0.006*\"blend\"'),\n",
       " (3,\n",
       "  '0.015*\"sugar\" + 0.009*\"salt\" + 0.008*\"calories\" + 0.008*\"sweet\" + 0.008*\"sauce\" + 0.007*\"chips\" + 0.007*\"add\" + 0.006*\"make\" + 0.006*\"fat\" + 0.006*\"low\"'),\n",
       " (4,\n",
       "  '0.012*\"dog\" + 0.007*\"day\" + 0.007*\"did\" + 0.006*\"bag\" + 0.006*\"know\" + 0.005*\"quality\" + 0.005*\"dogs\" + 0.005*\"didn\" + 0.005*\"weight\" + 0.005*\"bad\"'),\n",
       " (5,\n",
       "  '0.035*\"water\" + 0.016*\"hair\" + 0.015*\"coconut\" + 0.015*\"oil\" + 0.014*\"bottle\" + 0.012*\"popcorn\" + 0.011*\"drink\" + 0.010*\"energy\" + 0.007*\"juice\" + 0.006*\"using\"'),\n",
       " (6,\n",
       "  '0.023*\"cat\" + 0.017*\"free\" + 0.015*\"cats\" + 0.013*\"chicken\" + 0.012*\"gluten\" + 0.011*\"old\" + 0.010*\"mix\" + 0.009*\"dry\" + 0.008*\"loves\" + 0.008*\"baby\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_corpus = matutils.Sparse2Corpus(counts_vec)\n",
    "id2word = dict((v, k) for k, v in vec.vocabulary_.items())\n",
    "lda = models.LdaModel(corpus=cv_corpus, num_topics=7, id2word=id2word, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's Give LSI a Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_corpus = matutils.Sparse2Corpus(tfidf_vec)\n",
    "\n",
    "# id2word2 = dict((v, k) for k, v in tfidf.vocabulary_.items())\n",
    "\n",
    "# lsi = models.LsiModel(tfidf_corpus, id2word=id2word2, num_topics=20)\n",
    "# lsi_corpus = lsi[tfidf_corpus]\n",
    "# doc_vecs = [doc for doc in lsi_corpus]\n",
    "# doc_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index our test text blobs\n",
    "test_index = similarities.MatrixSimilarity(lsi_corpus)\n",
    "\n",
    "# Iterate and print out all pairwise similarities\n",
    "# For each test text blob that we're looking at\n",
    "for i, sims in enumerate(test_index):\n",
    "    # We get a list of similarities to all indexed text blobs\n",
    "    # Print the text blob we're currently examining\n",
    "    print(\"Similarities to {}:\".format(text_blobs[i]))\n",
    "    # Print the similarities of the current blob to all others with labels\n",
    "    sims_with_labels = [(score, text_blobs[j]) for j, score in enumerate(sims)]\n",
    "    # Sort the results by decreasing similarity and print them out\n",
    "    sorted_sims_with_labels = sorted(sims_with_labels, reverse=True)\n",
    "    print(sorted_sims_with_labels)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Users ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = (reviews.groupby(['UserId'], as_index=False)\n",
    "           .agg(OrderedDict(\n",
    "               [('ProductId',(lambda x: list(x))),\n",
    "                ('Text', 'sum')])))\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = df_user['Text']\n",
    "\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                        analyzer='word',\n",
    "                        stop_words=stop_words,\n",
    "                        strip_accents='unicode',\n",
    "                        max_df=0.9\n",
    "                       )\n",
    "\n",
    "user_corpus = tfidf2.fit_transform(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf2 = NMF(5)\n",
    "\n",
    "user_vecs = nmf2.fit_transform(user_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = tfidf2.get_feature_names()\n",
    "user_topics = [[user_features[idx] for idx in np.flip(np.argsort(component)[-20:])] for component in nmf2.components_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics(user_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
